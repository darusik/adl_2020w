{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from random import choice\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Mask-Utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTURE_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACECOVER_ROOT = 'masks/'\n",
    "FACECOVER_EXT = '.png'\n",
    "FACECOVER_PATHS = list(sorted(str(p) for p in Path(FACECOVER_ROOT).glob('*' + FACECOVER_EXT)))\n",
    "assert len(FACECOVER_PATHS), 'Failed to find any masks in \"masks\" directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    face_boxes, tddfa = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = get_vertices_predictor(face_boxes, tddfa, is_cropped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_with_text(text, color):\n",
    "    image = np.full((333, 999, 3), dtype=np.uint8, fill_value=255) \n",
    "    image = cv2.putText(image, text, (100, 160), cv2.FONT_HERSHEY_SIMPLEX ,  \n",
    "                        1, color, 1, cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cover_face_with_mask(\n",
    "    image,\n",
    "    facecover_image,\n",
    "    cache=dict(\n",
    "        face_indicator = None,\n",
    "        convexer = None,\n",
    "        blur_mix_weights = None,\n",
    "        linear_nd_creator = CachedInterpolatorCreator(interpolate.LinearNDInterpolator),\n",
    "        linear_nd_ext_creator = CachedInterpolatorCreator(LinearNDInterpolatorExt),\n",
    "    )):\n",
    "    assert image is not None\n",
    "\n",
    "    try:\n",
    "        ver = predictor(image)\n",
    "    except IndexError:\n",
    "        return None\n",
    "        \n",
    "    texture = uv_tex(image, [ver], tddfa.tri, uv_h=TEXTURE_SIZE, uv_w=TEXTURE_SIZE)\n",
    "\n",
    "    uv_coords = get_uv_coords(TEXTURE_SIZE)\n",
    "    uv2ver_sparse = get_sparse_uv2ver(uv_coords, TEXTURE_SIZE, ver)\n",
    "    uv2ver = inpaint(uv2ver_sparse,\n",
    "                     mask=np.isnan(uv2ver_sparse).astype(np.uint8),\n",
    "                     interpolator_cls=cache['linear_nd_creator'])\n",
    "\n",
    "    if cache['face_indicator'] is None:\n",
    "        cache['face_indicator'] = get_face_indicator(uv2ver)\n",
    "    if cache['convexer'] is None:\n",
    "        cache['convexer'] = FixedConvexer(ver, uv_coords, cache['face_indicator'], uv2ver)\n",
    "    \n",
    "    convex_uv2ver_sparse = cache['convexer'](uv2ver)\n",
    "    convex_uv2ver = inpaint(convex_uv2ver_sparse,\n",
    "                            mask=np.isnan(convex_uv2ver_sparse).astype(np.uint8),\n",
    "                            interpolator_cls=cache['linear_nd_ext_creator'])\n",
    "\n",
    "    if cache['blur_mix_weights'] is None:\n",
    "        cache['blur_mix_weights'] = get_blur_weights(convex_uv2ver.shape)[..., None]\n",
    "    \n",
    "    blurred_convex_uv2ver = blur_multichannel(convex_uv2ver, sigma=(2.5, 5.0), mode='nearest')\n",
    "    convex_uv2ver = convex_uv2ver * (1.0 - cache['blur_mix_weights']) + blurred_convex_uv2ver * cache['blur_mix_weights']\n",
    "    \n",
    "    convex_mesh = get_mesh(convex_uv2ver, cache['face_indicator'], TEXTURE_SIZE, TEXTURE_SIZE)\n",
    "    \n",
    "    visible_skin = get_visible_skin(uv2ver)\n",
    "    target_lightness_ratio = get_cheeks_lightness_ratio(texture, visible_skin)\n",
    "    light_x = find_light_x_position(\n",
    "        target_lightness_ratio,\n",
    "        uv_coords, ver, tddfa.tri, texture, visible_skin,\n",
    "        render_app, image.shape,\n",
    "    )\n",
    "\n",
    "    facecover = FacecoverTextureWarper()(facecover_image, TEXTURE_SIZE)\n",
    "    facecover_tr = facecover_color_transfer(facecover, texture)\n",
    "    update_colors(convex_mesh, facecover_tr)\n",
    "\n",
    "    ambient_w, direct_w = get_lightning_params(target_lightness_ratio, light_x, facecover_tr)\n",
    "    \n",
    "    final_render = render_facecover(\n",
    "        render_app, convex_mesh, image, light_x, ambient_w, direct_w, return_intermediate=False\n",
    "    )     \n",
    "    return final_render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import re\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from cnn_finetune import make_model\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "class MaskDetector():\n",
    "    def __init__(self, model_path=\"mask_resnet18_epochs_5.pth\"):\n",
    "        search_model_name = re.search(r'.*mask_(.*)_epochs.*', model_path, flags=0)\n",
    "        assert search_model_name\n",
    "        model_name = search_model_name.group(1)\n",
    "        model = make_model(\n",
    "            model_name,\n",
    "            pretrained=False,\n",
    "            num_classes=2,\n",
    "            dropout_p=0.2,\n",
    "            input_size=(64, 64) if model_name.startswith(('vgg', 'squeezenet')) else None,\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        \n",
    "        self._model = model\n",
    "        self._transform = alb.Compose([\n",
    "            alb.Resize(64, 64),\n",
    "            alb.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = self._transform(image=image)['image']\n",
    "        return softmax(self._model(image[None, :]), dim=-1).detach().numpy().flatten()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_detector = MaskDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image_bgr):\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    score = mask_detector(image_rgb)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def img_to_value(img):\n",
    "    if img.ndim == 3:\n",
    "        img = img[..., ::-1]\n",
    "    buffer = BytesIO()\n",
    "    Image.fromarray(img).save(buffer, 'jpeg')\n",
    "    return buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = widgets.FileUpload(\n",
    "    accept='.jpg,.jpeg,.JPG,.JPEG,.png,.PNG',\n",
    "    multiple=False,\n",
    "    description='Upload an image with face',\n",
    "    layout=widgets.Layout(width='75%'),\n",
    ")\n",
    "upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_image():\n",
    "    if len(upload.value) == 0:\n",
    "        return None\n",
    "\n",
    "    input_buffer = next(iter(upload.value.values()))['content']\n",
    "    return cv2.imdecode(np.frombuffer(input_buffer, np.uint8), cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_preview = widgets.Image(\n",
    "    value=img_to_value(np.full((10, 10, 3), dtype=np.uint8, fill_value=255)),\n",
    "    format='jpg',\n",
    ")\n",
    "face_preview = widgets.Image(\n",
    "    value=img_to_value(np.full((10, 10, 3), dtype=np.uint8, fill_value=255)),\n",
    "    format='jpg',\n",
    ")\n",
    "classifier_preview = widgets.Image(\n",
    "    value=img_to_value(np.full((10, 10, 3), dtype=np.uint8, fill_value=255)),\n",
    "    format='jpg',\n",
    ")\n",
    "covered_face_preview = widgets.Image(\n",
    "    value=img_to_value(np.full((10, 10, 3), dtype=np.uint8, fill_value=255)),\n",
    "    format='jpg',\n",
    ")\n",
    "\n",
    "\n",
    "def update_input_preview(img):\n",
    "    if img is None:\n",
    "        preview = get_image_with_text('No image selected', (125, 125, 125))\n",
    "    elif img.shape[0] > 333:\n",
    "        f = 333.0 / img.shape[0]\n",
    "        preview = cv2.resize(img, None, fx=f, fy=f)\n",
    "    else:\n",
    "        preview = img.copy()\n",
    "\n",
    "    input_image_preview.value = img_to_value(preview)\n",
    "\n",
    "    \n",
    "def update_face_preview(face, err_text=None, err_color=None):\n",
    "    if face is None:\n",
    "        err_text = 'Failed to find a face' if err_text is None else err_text\n",
    "        err_color = (63, 0, 255) if err_color is None else err_color\n",
    "\n",
    "        face_preview.value = img_to_value(get_image_with_text(err_text, err_color))\n",
    "        classifier_preview.value = face_preview.value\n",
    "        covered_face_preview.value = face_preview.value\n",
    "    else:\n",
    "        if face.shape[0] > 333:\n",
    "            f = 333.0 / face.shape[0]\n",
    "            face = cv2.resize(face, None, fx=f, fy=f)\n",
    "        face_preview.value = img_to_value(face)\n",
    "\n",
    "\n",
    "def update_classifier_preview(prob):\n",
    "    GREEN = np.array([52, 203, 3])\n",
    "    YELLOW = np.array([10, 182, 240])\n",
    "    RED = np.array([63, 0, 255])\n",
    "    \n",
    "    text = f'Mask presence probability: {prob:.2f}'\n",
    "    if prob < 0.5:\n",
    "        raw_color = YELLOW * 2 * prob + RED * (1.0 - 2 * prob)\n",
    "    else:\n",
    "        raw_color = GREEN * 2 * (prob - 0.5) + YELLOW * (1.0 - 2 * (prob - 0.5))\n",
    "        \n",
    "    color = tuple(int(v) for v in raw_color)\n",
    "    classifier_preview.value = img_to_value(get_image_with_text(text, color))\n",
    "\n",
    "\n",
    "def update_covered_face_preview(covered):\n",
    "    if covered is None:\n",
    "        err_text = 'Please choose a person not wearing a mask'\n",
    "        err_color = (63, 0, 255)\n",
    "        covered_face_preview.value = img_to_value(get_image_with_text(err_text, err_color))\n",
    "    else:\n",
    "        covered_face_preview.value = img_to_value(covered)\n",
    "    \n",
    "    \n",
    "def on_image_update(*args, **kwargs):\n",
    "    img = get_input_image()\n",
    "    update_input_preview(img)\n",
    "\n",
    "    if img is None:\n",
    "        update_face_preview(None, 'Please select an image first', (125, 125, 125))\n",
    "        return\n",
    "\n",
    "    boxes = face_boxes(img)\n",
    "    if len(boxes) == 0:\n",
    "        update_face_preview(None)\n",
    "        return\n",
    "    \n",
    "    box = np.clip(np.round(np.array(boxes[0][:-1])).astype(int),\n",
    "                  [0, 0] * 2,\n",
    "                  [img.shape[1] - 1, img.shape[0] - 1] * 2)\n",
    "    face = img[box[1]:box[3], box[0]:box[2]]\n",
    "    update_face_preview(face)\n",
    "    \n",
    "    mask_prob = classify(image_bgr=face)\n",
    "    update_classifier_preview(mask_prob)\n",
    "    \n",
    "    if mask_prob > 0.5:\n",
    "        update_covered_face_preview(None)\n",
    "        return\n",
    "    \n",
    "    covered_face_preview.value = img_to_value(get_image_with_text('Working...', (125, 125, 125)))\n",
    "\n",
    "    facecover = cv2.imread(choice(FACECOVER_PATHS), cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0\n",
    "    covered = cover_face_with_mask(img, facecover)\n",
    "    assert covered is not None\n",
    "    \n",
    "    update_covered_face_preview(covered)\n",
    "\n",
    "on_image_update()    \n",
    "upload.observe(on_image_update, names=['_counter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(input_image_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detected face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(face_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(classifier_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covered face with a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(covered_face_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
